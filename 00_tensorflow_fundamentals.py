# -*- coding: utf-8 -*-
"""00_tensorflow_fundamentals.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W3mPeLke1jJJnLHBdYCo2HTFzKQ6AGx7

#in this notebbok we`re going to conver some of the most fundamentas concepts 

More specifically, we`re going to conver?
* introduction to tensors
* Getting information from tensors
* manipulating tensors
* Tensors e Numpy
* Using @tf.funtion 
* Using GPUs with tensors
* Exercicies

## Introduction
"""

# import tensorFlow

import tensorflow as tf
print(tf.__version__)

#create tensors with tf.constant()
scalar = tf.constant(7)
scalar

#check num dimensions
scalar.ndim

#create vector
vector = tf.constant([10, 10])
vector

#check dimensions vector
vector.ndim

#create matrix
matrix = tf.constant([[10, 10],
                      [3, 12]])

#check dim matrix
matrix.ndim

#crete another matrix 
another_matrix = tf.constant([[10., 7.],
                              [34., 23.],
                              [3., 3.]], dtype=tf.float16) # define data type parameters
another_matrix

# ndim of another matrix
another_matrix.ndim

#let's create a tensor
tensor = tf.constant([[[1, 2, 3,],
                       [4, 5, 6]],
                      [[7, 8, 9],
                       [10, 11, 12]],
                      [[13, 14, 15],
                       [16, 17, 18]]])
tensor

tensor.ndim

"""### Creating a tensor with tf.variable"""

#create the same tensor with tf.variable() as above
changeable_tensor = tf.Variable([10, 7])
unchangeable_tensor = tf.constant([10, 7])
changeable_tensor, unchangeable_tensor

#Let's try change in our changeable tensor
#changeable_tensor[0]=7

#Change wth assign
changeable_tensor[0].assign(7)
changeable_tensor

#creating two randon tensors
random_1 = tf.random.Generator.from_seed(42) # set seed fro reprodicibility
random_1 = random_1.normal(shape=(3, 2))

random_2 = tf.random.Generator.from_seed(42)
random_2 = random_2.normal(shape=(3, 2))

#Are they iqual?
random_1, random_2, random_1 == random_2

#shuffle the order 
not_shuffled = tf.constant([[2, 3],
                           [3, 3],
                           [4, 3]])
not_shuffled
not_shuffled.ndim


tf.random.set_seed(42) #set global random seed  
tf.random.shuffle(not_shuffled, seed=42) #operation level random seed
#not_shuffled

## others ways to make tensors

tf.ones([10, 7])

#create tensors with all zeros

tf.zeros(shape=(3, 4))

#turn numpy arrays into tensors obs: tensor can run in GPU and is so faster
import numpy as np
numpy_A= np.arange(1, 25, dtype=np.int32)
numpy_A
A = tf.constant(numpy_A, shape=(2, 3, 4))
A
#x = tf.constant(some_matrix)
#y = tf.constant(vector)

#create rank 4 tensor
rank_4_tensor = tf.zeros(shape=[2, 3, 4, 5])
rank_4_tensor[0]

rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)

#get various atributtes from our tensor

print("Datatype of every element: ", rank_4_tensor.dtype)
print("Number on dimension: ", rank_4_tensor.ndim)

#indexing tensors
#get first two elements of each dimension

rank_4_tensor[:2,:2, :2, :2]

"""#basic operations
tensor = tf.constant([[10, 7], [3, 4]])
tensor + 10

#original tensor is unchanged
tensor * 10

tensor /10
tensor -10

"""

#multiplication matrix operaton

tf.matmul(tensor, tensor)

tensor * tensor
tensor @ tensor

#create a new tensor for finding positional minimum  and maximum
tf.random.set_seed(42)
F = tf.random.uniform(shape=[50])
F

#max positioon

tf.argmax(F)

F[tf.argmax(F)]

#find max
tf.reduce_max(F)

#Check for equality
assert F[tf.argmax(F)] == tf.reduce_max(F)

#max positioon

tf.argmin(F)

F[tf.argmin(F)]

tf.reduce_min(F)

#squeeze a tensor (removing single dimensions)
tf.random.set_seed(42)
G = tf.constant(tf.random.uniform(shape=[50]), shape=(1,1,1,1, 50))
G

G.shape

G_squeezed = tf.squeeze(G)
G_squeezed, G_squeezed.shape

#One-hot eoncoding tensors

#create list of indices
some_list = [0, 1, 2, 3] # could be red, blue , green and purple

#one hot encode our list of indices
tf.one_hot(some_list, depth=4)

#specify custo values for one hot encoding

tf.one_hot(some_list, depth=4, on_value="yo I love deep learning", off_value="I also like dance")

## Suqaring, log square root

#Create a new tensor
H = tf.range(1, 10)
H

tf.square(H)

#Suqare root
tf.sqrt(tf.cast(H, dtype=tf.float32))

#Find the log
tf.math.log(tf.cast(H, dtype=tf.float32))

#Tensors and numpy

#create a tensor directly from numpy

J = tf.constant(np.array([3., 7., 10.]))
J

#Convert our tensor back to a numpy array
np.array(J), type(np.array(J))

#convert tensor J to a numpy array

J.numpy(), type(J.numpy())

#J = tf.constant([3.])
#J.numpy()[0]

#The defaults types each are slightly different
numpy_J = tf.constant(np.array([3., 7., 10.]))
tensor_J = tf.constant([3., 7., 10.])

#Check data type
numpy_J.dtype, tensor_J.dtype

import tensorflow as tf

##Fiding access to  GPU
tf.config.list_physical_devices("GPU")

!nvidia-smi

